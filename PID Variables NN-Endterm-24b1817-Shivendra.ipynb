{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c14f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['treeMLDstar;1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fCandidateSelFlag',\n",
       " 'fChi2PCAD0',\n",
       " 'fCosThetaStarD0',\n",
       " 'fCpaD0',\n",
       " 'fCpaXYD0',\n",
       " 'fDecayLengthD0',\n",
       " 'fDecayLengthNormalisedD0',\n",
       " 'fDecayLengthXYD0',\n",
       " 'fDecayLengthXYNormalisedD0',\n",
       " 'fEta',\n",
       " 'fEtaD0',\n",
       " 'fFlagMcMatchRec',\n",
       " 'fImpParamSoftPi',\n",
       " 'fImpactParameter0',\n",
       " 'fImpactParameter1',\n",
       " 'fImpactParameterNormalised0',\n",
       " 'fImpactParameterNormalised1',\n",
       " 'fImpactParameterNormalisedSoftPi',\n",
       " 'fImpactParameterProductD0',\n",
       " 'fM',\n",
       " 'fMD0',\n",
       " 'fMaxNormalisedDeltaIPD0',\n",
       " 'fNSigTofKa0',\n",
       " 'fNSigTofKa1',\n",
       " 'fNSigTofKaSoftPi',\n",
       " 'fNSigTofPi0',\n",
       " 'fNSigTofPi1',\n",
       " 'fNSigTofPiSoftPi',\n",
       " 'fNSigTpcKa0',\n",
       " 'fNSigTpcKa1',\n",
       " 'fNSigTpcKaSoftPi',\n",
       " 'fNSigTpcPi0',\n",
       " 'fNSigTpcPi1',\n",
       " 'fNSigTpcPiSoftPi',\n",
       " 'fNSigTpcTofKa0',\n",
       " 'fNSigTpcTofKa1',\n",
       " 'fNSigTpcTofKaSoftPi',\n",
       " 'fNSigTpcTofPi0',\n",
       " 'fNSigTpcTofPi1',\n",
       " 'fNSigTpcTofPiSoftPi',\n",
       " 'fPhi',\n",
       " 'fPhiD0',\n",
       " 'fPt',\n",
       " 'fPtBhadMother',\n",
       " 'fPtD0',\n",
       " 'fPtProng0',\n",
       " 'fPtProng1',\n",
       " 'fPtSoftPi',\n",
       " 'fY',\n",
       " 'fYD0',\n",
       " 'fInvDeltaMass']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "\n",
    "file_prompt = uproot.open(\"Prompt_DstarToD0Pi.root\")\n",
    "tree_prompt = file_prompt[\"treeMLDstar\"]\n",
    "\n",
    "print(file_prompt.keys())\n",
    "tree_prompt.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (12949176, 14)\n",
      "y shape: (12949176,)\n",
      "First 10 labels: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "file_prompt = uproot.open(\"Prompt_DstarToD0Pi.root\")\n",
    "file_nonprompt = uproot.open(\"Nonprompt_DstarToD0Pi.root\")\n",
    "file_bkg = uproot.open(\"Bkg_DstarToD0Pi.root\")\n",
    "\n",
    "tree_prompt = file_prompt[\"treeMLDstar\"]\n",
    "tree_nonprompt = file_nonprompt[\"treeMLDstar\"]\n",
    "tree_bkg = file_bkg[\"treeMLDstar\"]\n",
    "\n",
    "# -----------------------------\n",
    "# Branches to load\n",
    "# -----------------------------\n",
    "\n",
    "branches = [\n",
    "    # Topological variables\n",
    "    \"fCpaD0\",\n",
    "    \"fCpaXYD0\",\n",
    "    \"fDecayLengthXYD0\",\n",
    "    \"fImpactParameterProductD0\",\n",
    "    \"fImpParamSoftPi\",\n",
    "    \"fMaxNormalisedDeltaIPD0\",\n",
    "\n",
    "    # PID prong0\n",
    "    \"fNSigTpcPi0\",\n",
    "    \"fNSigTpcKa0\",\n",
    "    \"fNSigTofPi0\",\n",
    "    \"fNSigTofKa0\",\n",
    "\n",
    "    # PID prong1\n",
    "    \"fNSigTpcPi1\",\n",
    "    \"fNSigTpcKa1\",\n",
    "    \"fNSigTofPi1\",\n",
    "    \"fNSigTofKa1\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Load arrays\n",
    "# -----------------------------\n",
    "\n",
    "arr_prompt = tree_prompt.arrays(branches, library=\"np\")\n",
    "arr_nonprompt = tree_nonprompt.arrays(branches, library=\"np\")\n",
    "arr_bkg = tree_bkg.arrays(branches, library=\"np\")\n",
    "\n",
    "# -----------------------------\n",
    "# Build feature matrices\n",
    "# -----------------------------\n",
    "\n",
    "def build_X(arr):\n",
    "    return np.column_stack([arr[b] for b in branches])\n",
    "\n",
    "X_prompt = build_X(arr_prompt)\n",
    "X_nonprompt = build_X(arr_nonprompt)\n",
    "X_bkg = build_X(arr_bkg)\n",
    "\n",
    "# -----------------------------\n",
    "# Create labels\n",
    "# -----------------------------\n",
    "\n",
    "y_prompt = np.zeros(len(X_prompt))        # 0\n",
    "y_nonprompt = np.ones(len(X_nonprompt))   # 1\n",
    "y_bkg = 2 * np.ones(len(X_bkg))            # 2\n",
    "\n",
    "# -----------------------------\n",
    "# Merge datasets\n",
    "# -----------------------------\n",
    "\n",
    "X = np.vstack((X_prompt, X_nonprompt, X_bkg))\n",
    "y = np.concatenate((y_prompt, y_nonprompt, y_bkg))\n",
    "\n",
    "# -----------------------------\n",
    "# Sanity checks\n",
    "# -----------------------------\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"First 10 labels:\", y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801cde27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.nan_to_num(X, nan=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b6110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of first feature (train): -9.1639365e-08\n",
      "Std of first feature (train): 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -----------------------------\n",
    "# Train-test split (70/30)\n",
    "# -----------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Feature normalization\n",
    "# -----------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit ONLY on training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply same transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# Sanity check\n",
    "# -----------------------------\n",
    "\n",
    "print(\"Mean of first feature (train):\", X_train_scaled[:,0].mean())\n",
    "print(\"Std of first feature (train):\", X_train_scaled[:,0].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5521eed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mD0Classifier\u001b[39;00m(nn.Module):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class D0Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D0Classifier, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(14, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 3)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)   # logits\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba5b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create model\n",
    "model = D0Classifier()\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (Adam)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "# Learning-rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=20,   # reduce LR every 20 epochs\n",
    "    gamma=0.5       # LR_new = LR_old * 0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c4779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X: 0\n",
      "Infs in X: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs in X:\", np.isnan(X).sum())\n",
    "print(\"Infs in X:\", np.isinf(X).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd5dae",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m     26\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m optimizer.step()\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Scheduler step\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kains\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\torch\\_tensor.py:630\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    622\u001b[39m         Tensor.backward,\n\u001b[32m    623\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    628\u001b[39m         inputs=inputs,\n\u001b[32m    629\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kains\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\torch\\autograd\\__init__.py:364\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    359\u001b[39m     retain_graph = create_graph\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kains\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\torch\\autograd\\graph.py:865\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    863\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    864\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Number of epochs\n",
    "n_epochs = 60\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_t)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, y_train_t)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "    # Store loss\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586afc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m.version.cuda)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.cuda.is_available())\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Set model to evaluation mode\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_test = model(X_test_t)\n",
    "    probs_test = torch.softmax(outputs_test, dim=1)\n",
    "    preds_test = torch.argmax(probs_test, dim=1).numpy()\n",
    "\n",
    "# -----------------------------\n",
    "# Accuracy\n",
    "# -----------------------------\n",
    "acc = accuracy_score(y_test, preds_test)\n",
    "print(\"Test Accuracy:\", acc)\n",
    "\n",
    "# -----------------------------\n",
    "# Confusion Matrix\n",
    "# -----------------------------\n",
    "cm = confusion_matrix(y_test, preds_test)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# -----------------------------\n",
    "# ROC: Prompt vs Rest\n",
    "# -----------------------------\n",
    "y_true_prompt = (y_test == 0).astype(int)\n",
    "scores_prompt = probs_test[:,0].numpy()\n",
    "\n",
    "fpr_p, tpr_p, _ = roc_curve(y_true_prompt, scores_prompt)\n",
    "auc_p = auc(fpr_p, tpr_p)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_p, tpr_p, label=f\"Prompt vs Rest (AUC = {auc_p:.3f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# ROC: Nonprompt vs Rest\n",
    "# -----------------------------\n",
    "y_true_np = (y_test == 1).astype(int)\n",
    "scores_np = probs_test[:,1].numpy()\n",
    "\n",
    "fpr_np, tpr_np, _ = roc_curve(y_true_np, scores_np)\n",
    "auc_np = auc(fpr_np, tpr_np)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_np, tpr_np, label=f\"Nonprompt vs Rest (AUC = {auc_np:.3f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6604aac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
